{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbrefadderURL = 'http://fbref.com'\n",
    "\n",
    "def ScrapBig5Page(url):\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    table = soup.find(\"table\", attrs={\"class\": \"stats_table\"})\n",
    "    data = dict({})\n",
    "    for tr in table.tbody.find_all(\"tr\"):\n",
    "        if tr.get(\"class\") != \"thead\":\n",
    "            for td in tr.find_all(\"td\"):\n",
    "                col = td.get(\"data-stat\").strip()\n",
    "                if col not in data:\n",
    "                    data[col] = []\n",
    "        \n",
    "                if col == \"squad\":\n",
    "                    data.get(col).append([td.a.contents[0],\n",
    "                                          td.img.get(\"src\"), \n",
    "                                          str(fbrefadderURL + td.a.get(\"href\"))])\n",
    "                elif col == \"country\":\n",
    "                    data.get(col).append(td.span.contents[0])\n",
    "                elif (col == \"top_team_scorers\" or col == \"top_keeper\"):\n",
    "                    data.get(col).append(td.a.contents[0])\n",
    "                elif (col == \"last_5\"):\n",
    "                    lst = []\n",
    "                    for div in td.div.find_all(\"div\"):\n",
    "                        lst.append(div.a.contents[0])\n",
    "                    data.get(col).append(lst)\n",
    "                else:\n",
    "                    data.get(col).append(td.contents[0])\n",
    "   \n",
    "    df = pd.DataFrame(data)      # Convert to DataFrame\n",
    "    df = df.groupby(df.country)  # Group Data by Country\n",
    "    # Assign Each Country with specific Data\n",
    "    italy,france,germany,spain,england = df.get_group('it'), df.get_group('fr'), df.get_group('de'), df.get_group('es'), df.get_group('eng') \n",
    "    return italy,france,germany,spain,england,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScrapTeamPage(url, players):\n",
    "    # Url - Team Url, \n",
    "    # players - True if you want total for all players \n",
    "    # players - False if you want simply opponent and squad total\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    table = soup.find(\"table\", attrs={\"class\": \"stats_table\"})\n",
    "    \n",
    "    if players: \n",
    "        looper = table.tbody.find_all(\"tr\")\n",
    "        data = dict({\"players\": []})\n",
    "    else:\n",
    "        looper = table.tfoot.find_all(\"tr\")\n",
    "        data = dict({\"team_type\": []})\n",
    "        \n",
    "    for tr in looper:\n",
    "        if players:\n",
    "            data.get(\"players\").append([tr.th.a.contents[0],tr.a.get(\"href\")])\n",
    "        else:\n",
    "            data.get(\"team_type\").append(str(tr.th.contents[0]))\n",
    "            \n",
    "        for td in tr.find_all(\"td\"):\n",
    "            col = td.get(\"data-stat\").strip()\n",
    "            if col not in data:\n",
    "                data[col] = []\n",
    "            \n",
    "            if players:\n",
    "                if col == \"nationality\":\n",
    "                    data.get(col).append(td.span.contents[1].strip())\n",
    "                elif col == \"matches\":\n",
    "                    data.get(col).append(\"\")\n",
    "                elif len(td.contents) > 0:\n",
    "                    if (col == \"npxg_per90\" or col == \"xa_per90\" or\n",
    "                        col == \"xg_per90\"):\n",
    "                        data.get(col).append(float(td.contents[0]))\n",
    "                    else:\n",
    "                        data.get(col).append(str(td.contents[0]))\n",
    "                        \n",
    "                else:\n",
    "                    if td.contents == []:\n",
    "                        data.get(col).append('0')\n",
    "                    else:\n",
    "                        data.get(col).append(str(td.contents[0]))\n",
    "            else:\n",
    "                if len(td.contents) > 0:\n",
    "                    data.get(col).append(str(td.contents[0]))\n",
    "                else:\n",
    "                    data.get(col).append(\"\")                \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 5 teams\n",
      "Finished 10 teams\n"
     ]
    }
   ],
   "source": [
    "big5url = \"https://fbref.com/en/comps/Big5/Big-5-European-Leagues-Stats\"\n",
    "\n",
    "italy,france,germany,spain,england,ALL = ScrapBig5Page(big5url)\n",
    "players = pd.DataFrame()\n",
    "iters = 0 \n",
    "for index,row in england.iterrows():\n",
    "    teamURL = row['squad'][2]\n",
    "    temp = ScrapTeamPage(teamURL, True)\n",
    "    players = pd.concat([temp,players], axis=0)\n",
    "    iters +=1\n",
    "    if iters % 5 == 0:\n",
    "        print(\"Finished \"+ str(iters) + \" teams\")\n",
    "    \n",
    "def per90sdiff(df, value): # \n",
    "    filtered_df = df.loc[df['minutes_90s'] >= str(value)] \n",
    "    return filtered_df\n",
    "\n",
    "def getSpecificPositon(df, pos): #FW,AM,RW,LW\n",
    "    # pos = \"att\", \"mid\", \"full\", \"def\", \"wing\"\n",
    "    if pos == \"att\":\n",
    "        values=['FW','AM','RW','LW']\n",
    "    elif pos == \"mid\":\n",
    "        values=['WM','RM','LM','CM','DM', 'MF']\n",
    "    elif pos == \"full\":\n",
    "        values=['FB','RB','LB']\n",
    "    elif pos == \"def\":\n",
    "        values=['CB']    \n",
    "    else : # pos == \"wing\"\n",
    "        values=['LW','RW']\n",
    "    \n",
    "    filtered_df = df.loc[df['position'].isin(values)]\n",
    "    return filtered_df\n",
    "\n",
    "per90sPlayers = per90sdiff(players, 5)\n",
    "players = getSpecificPositon(per90sPlayers, \"att\")\n",
    "\n",
    "fig = px.scatter(players, x=\"npxg_per90\", y=\"xa_per90\", text=\"players\", \n",
    "                 size_max=60,                  \n",
    "                 labels={\n",
    "                     \"npxg_per90\": \"NP Expected Goal\",\n",
    "                     \"xa_per90\": \"Expected Assist\",\n",
    "                     \"players\": \"Name\"\n",
    "                 },\n",
    "                title=\"NP Expected Goals vs Expected Assists per 90 - data by FBref\")\n",
    "\n",
    "fig.update_traces(textposition='top center')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
